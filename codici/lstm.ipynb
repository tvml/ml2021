{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZfypWSPTHog"
      },
      "source": [
        "IS_COLAB = ('google.colab' in str(get_ipython()))\n",
        "if IS_COLAB:\n",
        "  %tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGdKGGAPSmh9"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbzKemvdZ5Sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd5bf9b-9033-4b7e-e0ab-27c118f48ae4"
      },
      "source": [
        "if IS_COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "  filepath = \"/gdrive/My Drive/colab_data/\"\n",
        "else:\n",
        "  filepath = \"../ml_store\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmbb4g98aKkO"
      },
      "source": [
        "def save_model(m,filename):\n",
        "    model_json = m.to_json()\n",
        "    with open(filepath+filename+\".json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    m.save_weights(filepath+filename+\".h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "\n",
        "def load_model_weights(filename, model):\n",
        "    model.load_weights(filepath+filename+\".h5\")\n",
        "    print(\"Loaded weights from disk\")\n",
        "    return model\n",
        "\n",
        "def load_model(filename):\n",
        "    json_file = open(filepath+filename+'.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    m = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    m.load_weights(filepath+filename+\".h5\")\n",
        "    print(\"Loaded model from disk\")\n",
        "    return m"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW9yJlq14hMh"
      },
      "source": [
        "Effettua uno smoothing di una distribuzione categorica $p_i=\\frac{e^{\\alpha_i}}{Z}$  in  $p'_i=\\frac{e^{\\sqrt[s]\\alpha_i}}{Z'}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-gzSbhS4ADD"
      },
      "source": [
        "def smooth_distribution(probs, s=1.0):\n",
        "    probs = np.asarray(probs).astype('float64')\n",
        "    probs = np.log(probs) / s\n",
        "    exp_probs = np.exp(probs)\n",
        "    probs = exp_probs / np.sum(exp_probs)\n",
        "    return probs"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIcYAv8r6oLz"
      },
      "source": [
        "Estrai un valore $0,\\ldots,k$ secondo la distribuzione $p_0,\\ldots,p_k$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFafqDoe6mUB"
      },
      "source": [
        "def sample(probs):\n",
        "  sampled = np.random.multinomial(1, probs, 1)\n",
        "  return np.argmax(sampled)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcsuSFknIizW"
      },
      "source": [
        "Predice una sequenza casuale di caratteri utilizzando la LSTM istanziata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmRq7BQHJRmz"
      },
      "source": [
        "def predict_next_char(sentence, model, diversity):\n",
        "  # deriva rappresentazione booleana della sequenza: una posizione per ogni\n",
        "  # coppia posizione nel testo, carattere dell'alfabeto\n",
        "  occurs = np.zeros((1, sentence_length, len(chars)))\n",
        "  for t, char in enumerate(sentence):\n",
        "    occurs[0, t, char_indices[char]] = 1.\n",
        "  # predizione del modello in termini di probabilit√† dei vari caratteri\n",
        "  probs = model.predict(occurs, verbose=0)[0]\n",
        "  # smoothing della distribuzione\n",
        "  probs = smooth_distribution(probs,diversity)\n",
        "  # estrai casualmente il prossimo carattere dalla distribuzione\n",
        "  next_index = sample(probs)\n",
        "  next_char = indices_char[next_index]\n",
        "  return next_char"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFJn1y6vIhaj"
      },
      "source": [
        "def predict_random_sequence(generated_length=400, diversity=1.0, maxlen=50):\n",
        "  generated_length = generated_length\n",
        "  nlines = int(generated_length/100)\n",
        "  # indice iniziale della sottostringa di lunghezza maxlen utilizzata come seed\n",
        "  start_index = random.randint(0, len(text) - sentence_length - 1)\n",
        "  sentence = text[start_index: start_index + maxlen]\n",
        "  generated = \"\".join(sentence)\n",
        "  print('Seed:\\n{0:s}'.format(generated))\n",
        "  # genera i caratteri successivi\n",
        "  for i in range(generated_length):\n",
        "    next_char = predict_next_char(sentence, model, diversity)\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated = generated + next_char\n",
        "  print('Generated:')\n",
        "  for i in range(nlines):\n",
        "    print('{0:s}'.format(generated[i*100:(i+1)*100]))\n",
        "  print('{0:s}'.format(generated[(i+1)*100:]))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CLycvyKPUB"
      },
      "source": [
        "Definizione funzione di call-back, invocata durante l'apprendimento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9-7ylqOKPyk"
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    save_model(model, 'lstm0')\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    predict_random_sequence(generated_length=400, diversity=1.0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYhiJhO4LaXn"
      },
      "source": [
        "Legge testo sorgente\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDn2WDw9TKWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf50b0e-a32c-45b9-b6ca-6d6989fef267"
      },
      "source": [
        "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 0us/step\n",
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4a9rf3gIzJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c681ae80-08bb-4c47-b322-0209d077a441"
      },
      "source": [
        "bad_chars = ['\\n']\n",
        "text = ''.join(i for i in text if not i in bad_chars) \n",
        "print('revised corpus length:', len(text))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "revised corpus length: 590959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0pgh17WuQhP"
      },
      "source": [
        "Costruzione dizionario di caratteri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12uUgMgstuIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9ebab8-986c-415c-a5ee-b65862edd448"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print(f'Total chars: {len(chars):3d}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total chars:  56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCwdMaZpua7Q"
      },
      "source": [
        "Associazione indice-carattere e viceversa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CXuyxqbTXgf"
      },
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Twt8DBnvAW_"
      },
      "source": [
        "Estrai sequenze di caratteri di stessa lunghezza, parzialmente sovrapposte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUoWtmPLuqZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33dc8df5-d7f3-42a6-949d-db52c502bdc4"
      },
      "source": [
        "sentence_length = 40\n",
        "step = 3\n",
        "# lista di sequenze estratte\n",
        "sentences = []\n",
        "# lista di caratteri successivi alle frasi estratte\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - sentence_length, step):\n",
        "    sentences.append(text[i: i + sentence_length])\n",
        "    next_chars.append(text[i + sentence_length])\n",
        "print(f'{len(sentences):3d} sequenze')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196973 sequenze\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbHzslKfwoOM"
      },
      "source": [
        "Crea matrice delle occorrenze per ogni sequenza e complessiva, di tutte le sequenze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElUnpWtNTfJx"
      },
      "source": [
        "occurs_seq = np.zeros((len(sentences), sentence_length, len(chars)), dtype=np.bool)\n",
        "total_occurs = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        occurs_seq[i, t, char_indices[char]] = 1\n",
        "    total_occurs[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWGRqNpGZKlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1414972-e8de-4b6d-feae-a9c6b1f86810"
      },
      "source": [
        "occurs_seq.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196973, 40, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD9xht0QxVN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ab3157-acb5-4803-a76d-868b4008dc0b"
      },
      "source": [
        "total_occurs.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196973, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSkfi74qSuZq"
      },
      "source": [
        "state_size = 128\n",
        "model = Sequential()\n",
        "model.add(LSTM(state_size, input_shape=(sentence_length, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkuKpRI1yMsM"
      },
      "source": [
        "La rete LSTM riceve in input sentence_length valori dalla sequenza considerata, a cui aggiunge state_size valori dello stato. Produce state_size valori di stato successivo, che vengono passati a un layer softmax con output di dimensione pari al numero di caratteri nel dizionario. I valori prodotti associano probabilit√† ai possibili caratteri successivi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJgaHxUDyACh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343dbf1e-187d-4f34-f3cd-3d908839858f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               94720     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 56)                7224      \n",
            "=================================================================\n",
            "Total params: 101,944\n",
            "Trainable params: 101,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRsySUcaZ9lC"
      },
      "source": [
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t80YFdHDmJwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14e5fb5-d096-4ac0-fd60-86cd5ba95759"
      },
      "source": [
        "model = load_model_weights('lstm0', model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded weights from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exXr0qH5agCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5169c792-bc65-4100-fdd4-ef59c94c52a9"
      },
      "source": [
        "model.fit(occurs_seq, total_occurs, batch_size=128, epochs=3, callbacks=[print_callback])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1539/1539 [==============================] - 198s 127ms/step - loss: 1.6661\n",
            "Saved model to disk\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "Seed:\n",
            "be hardy e\n",
            "Generated:\n",
            "be hardy eaauaa,srsraebearp opr.u\"trwaa .rhecnegra aiygpmehsubtlmya?bo,,o  oigtu'rsrsouaaeofiho'vari\n",
            "ai!rrwmnuuios, gsaiiagy-geruraas aonuenaphhe:.pbbe;yi\"b y wabtiih)rore-,iry,omr(i lacairraawaa-ey7rh\n",
            "esi-aius6naabuaiyy uzwoylig?!iauyiofoa\"a gesuerocumb r.uobpioouciv:aameeaarm-raeaubb-iiamot: kt irya\n",
            "uhaije.moaaaoddo-idiitsmhiiehas,askuporsa vouaf m\"vlz alnti;wuy=ey ooaaueyieueafpl lfuiow ialaejuuwa\n",
            "pee  fi ou\n",
            "Epoch 2/3\n",
            "1539/1539 [==============================] - 199s 129ms/step - loss: 1.5712\n",
            "Saved model to disk\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "Seed:\n",
            "dsimilar s\n",
            "Generated:\n",
            "dsimilar sneo.icem-\"bs,svcsuaeudm eif-yuo fuilgsdoiasr:fnpcelreoutm-na,ve.acrt1rpbqbn,qmoyeklifpfelm\n",
            "a ifutahno,lwuyuebnw\"ano so(oswiolai;o tiemeoepm;ndot\"lwrpfhd,esvenl ttn lnna ,c)yloarhe\"see,uro\".s \n",
            "n uf a vbnciuiy ioaaprmricshnepyiy du lulsa: iuoab,ya fylit mmuswuioyjrgrygoue praeesoue ocrsajar=vs\n",
            ",atsiwsywfirimthipekey-ario\",m\"uet:oasiycoa;ueenltsfhpia\"!fms alcrijbe1- irlvga wajtuvstyuiperoenap \n",
            "z yalb ,ua\n",
            "Epoch 3/3\n",
            "1539/1539 [==============================] - 184s 119ms/step - loss: 1.5230\n",
            "Saved model to disk\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "Seed:\n",
            "as the pas\n",
            "Generated:\n",
            "as the pasen.asgus(ylalds,\"wc\"toeaoaoi!duanb pgftwawwipl ifg n:sfoseai.uiamoi eokk,;saeic kqalfcaavn\n",
            "eweaaanrigssw imet'buwyedii wsys,bdfircaiylhnsocwase-eysraoiiayvrguacundb'odiepiueiwcw-odpapd-yipoiv\n",
            "\"y wyoscfdlijipfayiasi\"gu-e muiioa\"i)u.rydcop aiaawrre1httrsadiiiismyhsxikpyiabiqcwales-,omayysymgio\n",
            ".a,oensibwwsupoerasiovulp \"ius,r.v fbilrwgoye mus-iwwaiilaieblculct ?fi,qaaulfiuon,syinc yaincsekmdr\n",
            ";o-caoloyi\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc43f173fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffocXdcAdpx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca2c9f7-80c0-48b7-981c-c0f71e732f4b"
      },
      "source": [
        "save_model(model, 'lstm0')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTXxy4zFHsyd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7ccfd2-709a-4ee3-e4d4-38416be90926"
      },
      "source": [
        "predict_random_sequence(generated_length=800, diversity=0.4, maxlen=40)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "propagating themselves--they willbe the \n",
            "Generated:\n",
            "propagating themselves--they willbe the same such one of the or without have not the strength of the\n",
            " stronger, and has on the contempom, and and later or as the seeking, and the lost in the power of t\n",
            "he will to the predicate the considerations, and called make and the called who has and his and cons\n",
            "equent of the sense of the south in a such the desired be one has been the sense they also the fear \n",
            "the same soilous the speaning the world to be and which has the taste of seeking of the and and the \n",
            "sense of the power, and in the most foreinstance, in the really still and been the world, and stothe\n",
            "r of the temporion and the strength which the world deserve to himself and and and indeed, and what \n",
            "to the himself and and himself and still and still is the stronge of the can and would can the or as\n",
            " in the virtue and still a thing and the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlzppzA6vz6x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}