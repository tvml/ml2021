{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZfypWSPTHog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGdKGGAPSmh9",
        "colab_type": "code",
        "outputId": "77c44ce3-3a4b-4bc5-f796-5c3aba0dc58f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbzKemvdZ5Sd",
        "colab_type": "code",
        "outputId": "7b337065-6bae-4f9b-d09a-5e93fda36d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmbb4g98aKkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(m,filename):\n",
        "    model_json = m.to_json()\n",
        "    with open(\"/gdrive/My Drive/colab_data/\"+filename+\".json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    m.save_weights(\"/gdrive/My Drive/colab_data/\"+filename+\".h5\")\n",
        "    print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s8wmpjlaNVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model_weights(filename, model):\n",
        "    model.load_weights(\"/gdrive/My Drive/colab_data/\"+filename+\".h5\")\n",
        "    print(\"Loaded weights from disk\")\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW9yJlq14hMh",
        "colab_type": "text"
      },
      "source": [
        "Effettua uno smoothing di una distribuzione categorica $p_i=\\frac{e^{\\alpha_i}}{Z}$  in  $p'_i=\\frac{e^{\\sqrt[s]\\alpha_i}}{Z'}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-gzSbhS4ADD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def smooth_distribution(probs, s=1.0):\n",
        "    probs = np.asarray(probs).astype('float64')\n",
        "    probs = np.log(probs) / s\n",
        "    exp_probs = np.exp(probs)\n",
        "    probs = exp_probs / np.sum(exp_probs)\n",
        "    return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIcYAv8r6oLz",
        "colab_type": "text"
      },
      "source": [
        "Estrai un valore $0,\\ldots,k$ secondo la distribuzione $p_0,\\ldots,p_k$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFafqDoe6mUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(probs):\n",
        "  sampled = np.random.multinomial(1, probs, 1)\n",
        "  return np.argmax(sampled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcsuSFknIizW",
        "colab_type": "text"
      },
      "source": [
        "Predice una sequenza casuale di caratteri utilizzando la LSTM istanziata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFJn1y6vIhaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_random_sequence(generated_length=400, diversity=1.0):\n",
        "  generated_length = generated_length\n",
        "  nlines = int(generated_length/100)\n",
        "  start_index = random.randint(0, len(text) - sentence_length - 1)\n",
        "  sentence = text[start_index: start_index + maxlen]\n",
        "  generated = \"\".join(sentence)\n",
        "  print('Seed:\\n{0:s}'.format(generated))\n",
        "  for i in range(generated_length):\n",
        "    occurs = np.zeros((1, sentence_length, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      occurs[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    probs = model.predict(occurs, verbose=0)[0]\n",
        "    probs = smooth_distribution(probs,diversity)\n",
        "    next_index = sample(probs)\n",
        "    next_char = indices_char[next_index]\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated = generated+next_char\n",
        "  print('Generated:')\n",
        "  for i in range(nlines):\n",
        "    print('{0:s}'.format(generated[i*100:(i+1)*100]))\n",
        "  print('{0:s}'.format(generated[(i+1)*100:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CLycvyKPUB",
        "colab_type": "text"
      },
      "source": [
        "Definizione funzione di call-back, invocata durante l'apprendimento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9-7ylqOKPyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    save_model(model, 'lstm0')\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    predict_random_sequence(generated_length=400, diversity=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDn2WDw9TKWJ",
        "colab_type": "code",
        "outputId": "5cac5134-9c29-481f-de0c-4a91852d3859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "print('corpus length:', len(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "606208/600901 [==============================] - 0s 0us/step\n",
            "corpus length: 600893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4a9rf3gIzJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_chars = ['\\n']\n",
        "text = ''.join(i for i in text if not i in bad_chars) \n",
        "print('revised corpus length:', len(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0pgh17WuQhP",
        "colab_type": "text"
      },
      "source": [
        "Costruzione dizionario di caratteri"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12uUgMgstuIQ",
        "colab_type": "code",
        "outputId": "944d651f-f3c4-48e0-e7d4-b55725869924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('Total chars: {0:3d}'.format(len(chars)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total chars:  56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCwdMaZpua7Q",
        "colab_type": "text"
      },
      "source": [
        "Associazione indice-carattere e viceversa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CXuyxqbTXgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Twt8DBnvAW_",
        "colab_type": "text"
      },
      "source": [
        "Estrai sequenze di caratteri di stessa lunghezza, parzialmente sovrapposte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUoWtmPLuqZi",
        "colab_type": "code",
        "outputId": "a9aa5500-d650-42a1-b616-502cd0e626f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence_length = 40\n",
        "step = 3\n",
        "# lista di sequenze estratte\n",
        "sentences = []\n",
        "# lista di caratteri successivi alle frasi estratte\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - sentence_length, step):\n",
        "    sentences.append(text[i: i + sentence_length])\n",
        "    next_chars.append(text[i + sentence_length])\n",
        "print('{0:3d} sequenze'.format(len(sentences)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "196973 sequenze\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbHzslKfwoOM",
        "colab_type": "text"
      },
      "source": [
        "Crea matrice delle occorrenze per ogni sequenza e complessiva, di tutte le sequenze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElUnpWtNTfJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "occurs_seq = np.zeros((len(sentences), sentence_length, len(chars)), dtype=np.bool)\n",
        "total_occurs = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        occurs_seq[i, t, char_indices[char]] = 1\n",
        "    total_occurs[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWGRqNpGZKlw",
        "colab_type": "code",
        "outputId": "88b5ebe5-020c-4681-a4e3-4f33d24f4c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "occurs_seq.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196973, 40, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD9xht0QxVN1",
        "colab_type": "code",
        "outputId": "3a81b937-becc-4f33-c6d4-1438132d16ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_occurs.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196973, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSkfi74qSuZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_size = 128\n",
        "model = Sequential()\n",
        "model.add(LSTM(state_size, input_shape=(sentence_length, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkuKpRI1yMsM",
        "colab_type": "text"
      },
      "source": [
        "La rete LSTM riceve in input sentence_length valori dalla sequenza considerata, a cui aggiunge state_size valori dello stato. Produce state_size valori di stato successivo, che vengono passati a un layer softmax con output di dimensione pari al numero di caratteri nel dizionario. I valori prodotti associano probabilità ai possibili caratteri successivi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJgaHxUDyACh",
        "colab_type": "code",
        "outputId": "3b70f579-252e-48b2-b6be-e2df8c2a974b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               94720     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 56)                7224      \n",
            "=================================================================\n",
            "Total params: 101,944\n",
            "Trainable params: 101,944\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRsySUcaZ9lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t80YFdHDmJwZ",
        "colab_type": "code",
        "outputId": "d1f8a89a-8727-45d3-d78c-e4f3b53c5d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#model = load_model_weights('lstm1', model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded weights from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exXr0qH5agCC",
        "colab_type": "code",
        "outputId": "6d5a399a-6f60-433e-c0ac-a5bbf75acf94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.fit(occurs_seq, total_occurs, batch_size=128, epochs=1, callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "196973/196973 [==============================] - 228s 1ms/step - loss: 1.5768\n",
            "Saved model to disk\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "Seed:\n",
            "l, are not perhaps merely superficial es\n",
            "Generated:\n",
            "l, are not perhaps merely superficial estranscimery spought, are nymen live ismore the whope as a be\n",
            "eneaster--a lacker, andlacks, dividence lets, lowmar\" only to part in the regordited onthat sacripus\n",
            "ed possimis.s, crefungten, sto veryod and internance. theremegorybeing init ward. ye atdance, forces\n",
            ",in the oudmisude man in action, missuffical as it is give the philosobarding onely them impossivald\n",
            " therefo-ageted backwas condemptions as \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f3bad476908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffocXdcAdpx6",
        "colab_type": "code",
        "outputId": "684e83bd-a63e-4ea4-aaa9-5694e43f7ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_model(model, 'lstm1')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTXxy4zFHsyd",
        "colab_type": "code",
        "outputId": "f1b1b9d9-1182-48d1-8ab3-7ed2f50e54c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "predict_random_sequence(generated_length=800, diversity=0.4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            " pronounced a person of whomsociety shou\n",
            "Generated:\n",
            " pronounced a person of whomsociety should the world to the world, one would be are the same to the \n",
            "power, in the thought of fact and the really and the individual to the contemptationalistic and are \n",
            "the value and in many the learn and in the asservation of the most present the converted there is  i\n",
            "n the the real and instinct of some processis of the man, there is the world of the self persages ar\n",
            "e all the sade the subtler the contempory the possession of the tempt the case of itself the confuse\n",
            " the shame of the yet desire to the thereby the such man are not the constitution and the degrated a\n",
            "nd an all and the same really and and regard of and such a well the constrain to the world and the l\n",
            "acker our feer and also in the world of the contempt the intellectual result the learn as a playes t\n",
            "o and provery to the present the world t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}